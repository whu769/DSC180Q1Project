{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\halom\\anaconda3\\envs\\test\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "import torch\n",
    "from collections import Counter\n",
    "import string\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"code_search_net\", \"all\")\n",
    "\n",
    "dataset_dict = datasets.load_from_disk(\"./Dataset/CodeSearchCorpus/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "CUDA device: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Testing if the pytorch GPU functions work\n",
    "print(torch.backends.cudnn.enabled)\n",
    "print(torch.cuda.is_available()) #We have GPU on deck and ready\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880853\n",
      "89154\n",
      "100529\n"
     ]
    }
   ],
   "source": [
    "# Seeing the size of the CodeSearchNet database\n",
    "print(len(dataset_dict[\"train\"]))\n",
    "print(len(dataset_dict[\"validation\"]))\n",
    "print(len(dataset_dict[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 1880853\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking only the training dataset\n",
    "train_dataset = dataset_dict[\"train\"]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the test_dataset\n",
    "# test_dataset = dataset_dict[\"test\"]\n",
    "# test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, 1.8M is too much. For week 5 at least, we've decided to train on a random sample of 10k from the training, 1k validation and 1k test\n",
    "\n",
    "Column for semantic search: func_documentation_string\n",
    "Column for tfidf: func_code_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository_name': 'ageitgey/face_recognition',\n",
       " 'func_path_in_repository': 'examples/face_recognition_knn.py',\n",
       " 'func_name': 'train',\n",
       " 'whole_func_string': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf',\n",
       " 'language': 'python',\n",
       " 'func_code_string': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf',\n",
       " 'func_code_tokens': ['def',\n",
       "  'train',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'model_save_path',\n",
       "  '=',\n",
       "  'None',\n",
       "  ',',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'None',\n",
       "  ',',\n",
       "  'knn_algo',\n",
       "  '=',\n",
       "  \"'ball_tree'\",\n",
       "  ',',\n",
       "  'verbose',\n",
       "  '=',\n",
       "  'False',\n",
       "  ')',\n",
       "  ':',\n",
       "  'X',\n",
       "  '=',\n",
       "  '[',\n",
       "  ']',\n",
       "  'y',\n",
       "  '=',\n",
       "  '[',\n",
       "  ']',\n",
       "  '# Loop through each person in the training set',\n",
       "  'for',\n",
       "  'class_dir',\n",
       "  'in',\n",
       "  'os',\n",
       "  '.',\n",
       "  'listdir',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ')',\n",
       "  ':',\n",
       "  'if',\n",
       "  'not',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'isdir',\n",
       "  '(',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'join',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  ')',\n",
       "  ':',\n",
       "  'continue',\n",
       "  '# Loop through each training image for the current person',\n",
       "  'for',\n",
       "  'img_path',\n",
       "  'in',\n",
       "  'image_files_in_folder',\n",
       "  '(',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'join',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  ')',\n",
       "  ':',\n",
       "  'image',\n",
       "  '=',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'load_image_file',\n",
       "  '(',\n",
       "  'img_path',\n",
       "  ')',\n",
       "  'face_bounding_boxes',\n",
       "  '=',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'face_locations',\n",
       "  '(',\n",
       "  'image',\n",
       "  ')',\n",
       "  'if',\n",
       "  'len',\n",
       "  '(',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '!=',\n",
       "  '1',\n",
       "  ':',\n",
       "  '# If there are no people (or too many people) in a training image, skip the image.',\n",
       "  'if',\n",
       "  'verbose',\n",
       "  ':',\n",
       "  'print',\n",
       "  '(',\n",
       "  '\"Image {} not suitable for training: {}\"',\n",
       "  '.',\n",
       "  'format',\n",
       "  '(',\n",
       "  'img_path',\n",
       "  ',',\n",
       "  '\"Didn\\'t find a face\"',\n",
       "  'if',\n",
       "  'len',\n",
       "  '(',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '<',\n",
       "  '1',\n",
       "  'else',\n",
       "  '\"Found more than one face\"',\n",
       "  ')',\n",
       "  ')',\n",
       "  'else',\n",
       "  ':',\n",
       "  '# Add face encoding for current image to the training set',\n",
       "  'X',\n",
       "  '.',\n",
       "  'append',\n",
       "  '(',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'face_encodings',\n",
       "  '(',\n",
       "  'image',\n",
       "  ',',\n",
       "  'known_face_locations',\n",
       "  '=',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '[',\n",
       "  '0',\n",
       "  ']',\n",
       "  ')',\n",
       "  'y',\n",
       "  '.',\n",
       "  'append',\n",
       "  '(',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  '# Determine how many neighbors to use for weighting in the KNN classifier',\n",
       "  'if',\n",
       "  'n_neighbors',\n",
       "  'is',\n",
       "  'None',\n",
       "  ':',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'int',\n",
       "  '(',\n",
       "  'round',\n",
       "  '(',\n",
       "  'math',\n",
       "  '.',\n",
       "  'sqrt',\n",
       "  '(',\n",
       "  'len',\n",
       "  '(',\n",
       "  'X',\n",
       "  ')',\n",
       "  ')',\n",
       "  ')',\n",
       "  ')',\n",
       "  'if',\n",
       "  'verbose',\n",
       "  ':',\n",
       "  'print',\n",
       "  '(',\n",
       "  '\"Chose n_neighbors automatically:\"',\n",
       "  ',',\n",
       "  'n_neighbors',\n",
       "  ')',\n",
       "  '# Create and train the KNN classifier',\n",
       "  'knn_clf',\n",
       "  '=',\n",
       "  'neighbors',\n",
       "  '.',\n",
       "  'KNeighborsClassifier',\n",
       "  '(',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'n_neighbors',\n",
       "  ',',\n",
       "  'algorithm',\n",
       "  '=',\n",
       "  'knn_algo',\n",
       "  ',',\n",
       "  'weights',\n",
       "  '=',\n",
       "  \"'distance'\",\n",
       "  ')',\n",
       "  'knn_clf',\n",
       "  '.',\n",
       "  'fit',\n",
       "  '(',\n",
       "  'X',\n",
       "  ',',\n",
       "  'y',\n",
       "  ')',\n",
       "  '# Save the trained KNN classifier',\n",
       "  'if',\n",
       "  'model_save_path',\n",
       "  'is',\n",
       "  'not',\n",
       "  'None',\n",
       "  ':',\n",
       "  'with',\n",
       "  'open',\n",
       "  '(',\n",
       "  'model_save_path',\n",
       "  ',',\n",
       "  \"'wb'\",\n",
       "  ')',\n",
       "  'as',\n",
       "  'f',\n",
       "  ':',\n",
       "  'pickle',\n",
       "  '.',\n",
       "  'dump',\n",
       "  '(',\n",
       "  'knn_clf',\n",
       "  ',',\n",
       "  'f',\n",
       "  ')',\n",
       "  'return',\n",
       "  'knn_clf'],\n",
       " 'func_documentation_string': 'Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.',\n",
       " 'func_documentation_tokens': ['Trains',\n",
       "  'a',\n",
       "  'k',\n",
       "  '-',\n",
       "  'nearest',\n",
       "  'neighbors',\n",
       "  'classifier',\n",
       "  'for',\n",
       "  'face',\n",
       "  'recognition',\n",
       "  '.'],\n",
       " 'split_name': 'train',\n",
       " 'func_code_url': 'https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition_knn.py#L46-L108'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing what one sample row of the training dataset is like\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverted_index_50000.pkl train_subset_embeddings_dataset_50000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Decide number of rows, the filepath to where to store the pickle files\n",
    "# The pickled objects are are the inverted index and embeddings dataset\n",
    "\n",
    "num_rows = 50000\n",
    "filepath_pkl_obj = \"./PickleObjects/\"\n",
    "inverted_index_name = f\"inverted_index_{num_rows}.pkl\"\n",
    "tsed_name = f\"train_subset_embeddings_dataset_{num_rows}.pkl\"\n",
    "\n",
    "print(inverted_index_name, tsed_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a sample of the training dataset\n",
    "# There are SO MANY PROBLEMS WHEN WE DO THIS THO, need to ask colin what to do i suppose?\n",
    "\n",
    "np.random.seed(1)\n",
    "train_subset_indices = np.random.choice(len(train_dataset), num_rows, replace = False)\n",
    "train_dataset_subset = train_dataset.select(train_subset_indices)\n",
    "\n",
    "len(train_dataset_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Embeddings Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following code from: https://huggingface.co/learn/nlp-course/chapter5/6?fw=pt\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\" #Can/Should test different models\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model to the GPU. Mine is a 3060\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Hugging Face Tutorials\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train embeddings\n",
    "#If the filename exists, load the pickle object. If not, train it and then save it as a pickle object\n",
    "#REMEMBER TO KEEP THE FILENAMES THE SAME 0_0\n",
    "try:\n",
    "    with open(f'{filepath_pkl_obj}{tsed_name}', 'rb') as f:  # open a text file\n",
    "        train_subset_embeddings_dataset = pickle.load(f) # serialize the list\n",
    "        f.close()\n",
    "except:\n",
    "    train_subset_embeddings_dataset = train_dataset_subset.map(\n",
    "        lambda x: {\"embeddings\": get_embeddings(x[\"func_documentation_string\"]).detach().cpu().numpy()[0]}\n",
    "    )\n",
    "\n",
    "    train_subset_embeddings_dataset.add_faiss_index(column=\"embeddings\")\n",
    "\n",
    "    with open(f'{filepath_pkl_obj}{tsed_name}', 'wb') as f:  # open a text file\n",
    "        pickle.dump(train_subset_embeddings_dataset, f) # serialize the list\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url', 'embeddings'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset_embeddings_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url', 'embeddings'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset_embeddings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the embeddings to a pandas dataframe\n",
    "tsed_DF = train_subset_embeddings_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the code tokens. Super rudimentary, \n",
    "# as of right now, we're just taking rid of the single punctuation\n",
    "def clean_code_tokens(lst):\n",
    "    result = string.punctuation \n",
    "    new_lst = [] \n",
    "    for character in lst:\n",
    "        if character in result:\n",
    "            continue\n",
    "        else:\n",
    "            new_lst.append(character)\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column of \"clean\" code tokens\n",
    "# There's many many issues with this strategy\n",
    "tsed_DF[\"clean_code_tokens\"] =  tsed_DF[\"func_code_tokens\"].apply(clean_code_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Much of this code was based off of William Scott's implementation of TF-IDF: https://github.com/williamscott701/Information-Retrieval/blob/master/2.%20TF-IDF%20Ranking%20-%20Cosine%20Similarity%2C%20Matching%20Score/TF-IDF.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates s list of documents\n",
    "documents = tsed_DF[\"clean_code_tokens\"].to_dict()\n",
    "\n",
    "# Compiles a list of the words \n",
    "all_words = []\n",
    "for i in list(tsed_DF[\"clean_code_tokens\"].to_dict().values()):\n",
    "    all_words += i\n",
    "\n",
    "#convert all words to a set, eliminates, duplicates\n",
    "all_words = list(set(all_words)) #Get rid of all repeats\n",
    "# all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./PickleObjects/inverted_index_50000.pkl'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{filepath_pkl_obj}{inverted_index_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted_index tf_idf\n",
    "tf_idf = create_tfidf(num_rows, tsed_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into much more efficient method of querying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_query(query_string, inverted_index, tf_idf, k = 10):\n",
    "    query_tokens = query_string.split()\n",
    "\n",
    "    rel_indices = []\n",
    "    \n",
    "    for token in query_tokens:\n",
    "        if token in inverted_index:\n",
    "            rel_indices += list(inverted_index[token].keys())\n",
    "    \n",
    "    rel_indices = set(rel_indices)\n",
    "\n",
    "    result_lst = []\n",
    "    for i in rel_indices:\n",
    "        for token in query_tokens:\n",
    "            score = 0\n",
    "            try:\n",
    "                score += (tf_idf[(i, token)])\n",
    "            except: continue\n",
    "        result_lst.append([i, score])\n",
    "    \n",
    "    result_lst.sort(reverse=True, key = lambda x: x[1])\n",
    "    return result_lst[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the inverted index if its not in a pickle file (and save it)\n",
    "def create_inverted_index(filepath_to_search):\n",
    "    try:\n",
    "        with open(filepath_to_search, 'rb') as f:\n",
    "            inverted_index = pickle.load(f) # deserialize using load()\n",
    "            f.close()\n",
    "    except:\n",
    "        inverted_index = {}\n",
    "        for i in range(num_rows):\n",
    "            token_counter = Counter(tsed_DF.iloc[i][\"clean_code_tokens\"])\n",
    "\n",
    "            for token in token_counter:\n",
    "                if token not in inverted_index:\n",
    "                    inverted_index[token] = {}\n",
    "                inverted_index[token][i] = token_counter[token]\n",
    "        \n",
    "        #Pickle afterwards\n",
    "        with open(filepath_to_search, 'wb') as f:  # open a text file\n",
    "            pickle.dump(inverted_index, f) # serialize the list\n",
    "            f.close()\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = create_inverted_index(f'{filepath_pkl_obj}{inverted_index_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tf_idf object. WILL TURN THIS INTO A FUNCTION LATER\n",
    "def create_tfidf(num_rows, tsed_DF):\n",
    "    tf_idf = {}\n",
    "    for i in range(num_rows):\n",
    "        # print(i)\n",
    "        tokens = tsed_DF[\"clean_code_tokens\"].iloc[i]\n",
    "        counter = Counter(tokens)\n",
    "        words_count = len(tokens)\n",
    "\n",
    "        for token in np.unique(tokens):\n",
    "            tf = counter[token] / words_count\n",
    "            df = len(inverted_index[token])\n",
    "            idf = np.log((num_rows + 1) / (df + 1))\n",
    "\n",
    "            tf_idf[i, token] = tf * idf\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted_index tf_idf\n",
    "tf_idf = create_tfidf(num_rows, tsed_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into much more efficient method of querying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for cosine_similarity. #Look into np.cos Annoy FAISS. look into applying and vectorizing\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_results(query_string, inverted_index, tf_idf, k = 10):\n",
    "    query_tokens = query_string.split()\n",
    "\n",
    "    rel_indices = []\n",
    "    \n",
    "    for token in query_tokens:\n",
    "        if token in inverted_index:\n",
    "            rel_indices += list(inverted_index[token].keys())\n",
    "    \n",
    "    rel_indices = set(rel_indices)\n",
    "\n",
    "    query_embedding = get_embeddings([\"string to date\"]).cpu().detach().numpy()\n",
    "    # len(query_embedding[0])\n",
    "    # len(tsed_DF[\"embeddings\"][0])\n",
    "    \n",
    "\n",
    "    result_lst = []\n",
    "    for i in rel_indices:\n",
    "        for token in query_tokens:\n",
    "            tf_score = 0\n",
    "            try:\n",
    "                tf_score += (tf_idf[(i, token)])\n",
    "            except: continue #this is bad, make sure this isn't the play\n",
    "        # print(i)\n",
    "\n",
    "        result_lst.append([i, tf_score, cosine_sim(tsed_DF[\"embeddings\"][i], query_embedding[0])])\n",
    "    \n",
    "    result_lst.sort(reverse=True, key = lambda x: 0.5 * x[1] + 0.5*x[2])\n",
    "    return result_lst[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_results = query_results(\"string to date\", inverted_index, tf_idf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19040, 1.913807353640272, 0.5304062],\n",
       " [8903, 1.6193754530802302, 0.67891794],\n",
       " [24467, 1.6745814344352379, 0.43565905],\n",
       " [2617, 1.4034587260028661, 0.4528301],\n",
       " [30965, 1.315742555627687, 0.50129217],\n",
       " [18983, 1.315742555627687, 0.48587227],\n",
       " [24729, 1.2383459347084111, 0.5489989],\n",
       " [34231, 1.3581858638737414, 0.41593793],\n",
       " [48278, 1.0525940445021496, 0.66434515],\n",
       " [28433, 1.1512747361742262, 0.51342237]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tqr in test_query_results:\n",
    "#     display(tsed_DF.iloc[tqr[0]][[\"func_name\", \"language\",  \"func_code_string\", \"func_documentation_string\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which runs all 99 queries, and returns a pd df of the results\n",
    "def create_results(query_filepath, results_per_query = 100):\n",
    "    queries = pd.read_csv(query_filepath)\n",
    "    # display(queries)\n",
    "    q_lst = queries[\"query\"].to_list()\n",
    "    # print(q_lst)\n",
    "\n",
    "    lang_lst = []\n",
    "    func_code_url_lst = []\n",
    "    query_lst = []\n",
    "\n",
    "    for i, query in enumerate(q_lst):\n",
    "        # print(i)\n",
    "        fbm_lst = query_results(query, inverted_index, tf_idf, results_per_query)\n",
    "        query_lst += [query for j in range(len(fbm_lst))]\n",
    "        \n",
    "        for lst in fbm_lst:\n",
    "            # print(tsed_DF.iloc[lst[0]][\"language\"])\n",
    "            # print(tsed_DF.iloc[lst[0]][\"func_name\"])\n",
    "            # print(tsed_DF.iloc[lst[0]][\"func_code_url\"])\n",
    "            # print(f\"SCORE: {lst[1]}\")\n",
    "            # print(\"-\" * 100)\n",
    "\n",
    "            lang_lst.append(tsed_DF.iloc[lst[0]][\"language\"])\n",
    "            func_code_url_lst.append(tsed_DF.iloc[lst[0]][\"func_code_url\"])\n",
    "        \n",
    "        # break\n",
    "\n",
    "    # print(lang_lst)\n",
    "    # print(func_code_url_lst)\n",
    "    # print(query_lst)\n",
    "    prediction_df = pd.DataFrame({'language' : lang_lst, 'url': func_code_url_lst, \"query\" : query_lst})\n",
    "    return prediction_df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = create_results(\"./Dataset/Testing/queries.csv\", results_per_query=50)\n",
    "res_df.to_csv(\"./csv_output/baseline_50k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for res in test_query_results:\n",
    "#     # print(len(tsed_DF.iloc[res[0]][\"embeddings\"]))\n",
    "#     print(\"-\" * 100)\n",
    "\n",
    "# query_embedding = get_embeddings([\"string to date\"]).cpu().detach().numpy()\n",
    "    \n",
    "    \n",
    "# desc_scores, desc_results = train_subset_embeddings_dataset.get_nearest_examples(\"embeddings\", query_embedding, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc_scores\n",
    "# desc_results.keys()\n",
    "# test_df = pd.DataFrame(desc_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repository_name', 'func_path_in_repository', 'func_name',\n",
       "       'whole_func_string', 'language', 'func_code_string', 'func_code_tokens',\n",
       "       'func_documentation_string', 'func_documentation_tokens', 'split_name',\n",
       "       'func_code_url', 'embeddings', 'clean_code_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tsed_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_embedding = get_embeddings([\"string to date\"]).cpu().detach().numpy()\n",
    "# len(query_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query_embedding = get_embeddings([\"string to date\"]).cpu().detach().numpy()\n",
    "# len(query_embedding[0])\n",
    "# len(tsed_DF[\"embeddings\"][0])\n",
    "# cosine_sim(tsed_DF[\"embeddings\"][0], query_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_query = \"string to date\"\n",
    "# test_query_tokens = test_query.split()\n",
    "# rel_indices = []\n",
    "# for token in test_query_tokens:\n",
    "#     # print(inverted_index[token])\n",
    "#     # print(token in inverted_index)\n",
    "    \n",
    "#     if token in inverted_index:\n",
    "#         print(len(list(inverted_index[token].keys())))\n",
    "#         rel_indices += list(inverted_index[token].keys())\n",
    "#     #     num_docs_with_term = (len(inverted_index[token]))\n",
    "#     #     for i in inverted_index[token].keys():\n",
    "#     #         print(tf_idf[(i, token)])\n",
    "\n",
    "# # len(rel_indices) == 2074 + 83 + 99\n",
    "# rel_indices = set(rel_indices)\n",
    "# len(rel_indices)\n",
    "\n",
    "# test_answers = []\n",
    "# for i in rel_indices:\n",
    "#     # print(i)\n",
    "#     for token in test_query_tokens:\n",
    "#         score = 0\n",
    "#         try:\n",
    "#             score += (tf_idf[(i, token)])\n",
    "#         except: continue\n",
    "#     test_answers.append([i, score])\n",
    "\n",
    "# test_answers.sort(key = lambda x: x[1], reverse=True)\n",
    "# test_answers[:10]\n",
    "# tsed_DF.iloc[19040]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_tf_idf\n",
    "# all_words_dict = dict(zip(all_words, range(len(all_words))))\n",
    "\n",
    "\n",
    "# tf_idf_array = np.zeros((num_rows, len(all_words)), dtype=\"float32\")\n",
    "\n",
    "# for i in tf_idf:\n",
    "#     try:\n",
    "#         ind = all_words_dict[i[1]]\n",
    "#         tf_idf_array[i[0]][ind] = tf_idf[i]\n",
    "#     except:\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get the document frequency of a word/token\n",
    "# def doc_freq(word):\n",
    "#     c = 0\n",
    "#     try:\n",
    "#         c = inverted_index[word]\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "#     if type(c) == list:\n",
    "#         return len(c)\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get the document frequency of a word/token\n",
    "# def doc_freq(word):\n",
    "#     c = 0\n",
    "#     try:\n",
    "#         c = inverted_index[word]\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "#     if type(c) == list:\n",
    "#         return len(c)\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which given a query, returns in a tf_idf vector\n",
    "# def gen_vector(s):\n",
    "#     # This is where we'd do more processing of the query\n",
    "#     tokens = s.split()\n",
    "\n",
    "#     q_vector = np.zeros((len(all_words)))\n",
    "    \n",
    "#     counter = Counter(tokens)\n",
    "#     words_count = len(tokens)\n",
    "\n",
    "#     for token in np.unique(tokens):\n",
    "        \n",
    "#         tf = counter[token]/words_count\n",
    "#         try:\n",
    "#             df = len(inverted_index[token])\n",
    "#         except:\n",
    "#             df = 0\n",
    "#         # df = doc_freq(token)\n",
    "#         idf = np.log((num_rows+1)/(df+1))\n",
    "\n",
    "#         try:\n",
    "#             ind = all_words_dict[token]\n",
    "#             q_vector[ind] = tf*idf\n",
    "#         except:\n",
    "#             pass\n",
    "#     return q_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_vector(\"pandas how to select first 10 rows\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_find_best_tfidf(query, df, colname):\n",
    "#     query_vector = gen_vector(query)\n",
    "#     df[\"cosine_sim\"] = df[colname].apply(lambda x: 1 - (spatial.distance.cosine(query_vector, x)))\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_find_best_tfidf(\"pandas how to select first 10 rows\", tsed_DF, \"tf_idf_vector\")\n",
    "# [ for x in range(num_rows)]\n",
    "# test_q_vector = gen_vector(\"pandas how to select first 10 rows\")\n",
    "# xa = tsed_DF[\"tf_idf_vector\"]\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code took 90s. That's buttcheeks\n",
    "# tsed_DF[\"tf_idf_vector\"].apply(lambda row: 1 - (spatial.distance.cosine(test_q_vector, row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (np.linalg.norm(xa, axis = 1) * np.linalg.norm(test_q_vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss.normalize_L2(xa)\n",
    "# vector_dimension = tf_idf_array.shape[1]\n",
    "# index = faiss.IndexFlatIP(vector_dimension)\n",
    "# faiss.normalize_L2(tf_idf_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.add(tf_idf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _vector = np.array([test_q_vector], dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss.normalize_L2(test_q_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _vector.shape\n",
    "# _vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_find_best_tfidf(\"pandas how to select first 10 rows\", tsed_DF, \"tf_idf_vector\")\n",
    "# [ for x in range(num_rows)]\n",
    "# test_q_vector = gen_vector(\"pandas how to select first 10 rows\")\n",
    "# xa = tsed_DF[\"tf_idf_vector\"]\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code took 90s. That's buttcheeks\n",
    "# tsed_DF[\"tf_idf_vector\"].apply(lambda row: 1 - (spatial.distance.cosine(test_q_vector, row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (np.linalg.norm(xa, axis = 1) * np.linalg.norm(test_q_vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss.normalize_L2(xa)\n",
    "# vector_dimension = tf_idf_array.shape[1]\n",
    "# index = faiss.IndexFlatIP(vector_dimension)\n",
    "# faiss.normalize_L2(tf_idf_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.add(tf_idf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _vector = np.array([test_q_vector], dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss.normalize_L2(test_q_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _vector.shape\n",
    "# _vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for cosine_similarity. #Look into np.cos Annoy FAISS. look into applying and vectorizing\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to find the best match\n",
    "# query param: the string query\n",
    "# k param: the k number of results to return\n",
    "# alpha: the value which determines the linear split alpha * tfidf portion + (1-alpha)*semantic search portion\n",
    "# def find_best_matches(query, k, alpha = 0.5):\n",
    "#     q_vector = gen_vector(query)\n",
    "#     # q_embedding_vector = get_embeddings([query]).cpu().detach().numpy()[0]\n",
    "    \n",
    "    \n",
    "#     cosine_lst = []\n",
    "    \n",
    "#     for i, x in enumerate(tf_idf_array):\n",
    "#         # col = tfidf_DF[x].to_numpy()\n",
    "#         # Tensor.cpu()\n",
    "#         # embedding = tsed_DF.iloc[i][\"embeddings\"]\n",
    "\n",
    "#         # cosine_lst[i] = [i, (alpha) * cosine_sim(q_vector, x) + (1 - alpha) * cosine_sim(q_embedding_vector, embedding)]\n",
    "\n",
    "#         # cosine_lst[i] = [i, (alpha) * 1 - (spatial.distance.cosine(q_vector, x))]\n",
    "#         cosine_lst.append([i, (alpha) * cosine_sim(q_vector, x)])\n",
    "    \n",
    "    \n",
    "#     cosine_lst.sort(reverse = True, key = lambda x: x[1])\n",
    "#     return cosine_lst[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_vector = gen_vector(\"pandas how to select first 10 rows\")\n",
    "\n",
    "# for i, x in enumerate(tf_idf_array):\n",
    "#     (cosine_sim(x, test_vector))\n",
    "\n",
    "# for i, x in enumerate(tf_idf_array):\n",
    "#     (1 - spatial.distance.cosine(x, test_vector))\n",
    "\n",
    "# tfidf_series = pd.Series(list(tf_idf_array))\n",
    "\n",
    "# vectorized_test = tfidf_series.apply(lambda x: cosine_sim(x, test_vector))\n",
    "\n",
    "# tfidf_series.apply(lambda x: np.dot(x, test_vector)/(np.linalg.norm(x)*np.linalg.norm(test_vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_best_matches(\"read csv to dataframe\", 10, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function which runs all 99 queries, and returns a pd df of the results\n",
    "# def create_results(query_filepath, results_per_query = 100):\n",
    "#     queries = pd.read_csv(query_filepath)\n",
    "#     # display(queries)\n",
    "#     q_lst = queries[\"query\"].to_list()\n",
    "#     # print(q_lst)\n",
    "\n",
    "#     lang_lst = []\n",
    "#     func_code_url_lst = []\n",
    "#     query_lst = []\n",
    "\n",
    "#     for i, query in enumerate(q_lst):\n",
    "#         print(i)\n",
    "#         fbm_lst = find_best_matches(query, results_per_query, 0.2)\n",
    "#         query_lst += [query for j in range(len(fbm_lst))]\n",
    "        \n",
    "#         for lst in fbm_lst:\n",
    "#             # print(tsed_DF.iloc[lst[0]][\"language\"])\n",
    "#             # print(tsed_DF.iloc[lst[0]][\"func_name\"])\n",
    "#             # print(tsed_DF.iloc[lst[0]][\"func_code_url\"])\n",
    "#             # print(f\"SCORE: {lst[1]}\")\n",
    "#             # print(\"-\" * 100)\n",
    "\n",
    "#             lang_lst.append(tsed_DF.iloc[lst[0]][\"language\"])\n",
    "#             func_code_url_lst.append(tsed_DF.iloc[lst[0]][\"func_code_url\"])\n",
    "        \n",
    "#         # break\n",
    "\n",
    "#     # print(lang_lst)\n",
    "#     # print(func_code_url_lst)\n",
    "#     # print(query_lst)\n",
    "#     prediction_df = pd.DataFrame({'language' : lang_lst, 'url': func_code_url_lst, \"query\" : query_lst})\n",
    "#     return prediction_df\n",
    "        \n",
    "# res_df = create_results(\"./Dataset/Testing/queries.csv\", results_per_query=50)\n",
    "# res_df.to_csv(\"./csv_output/baseline_20k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSC180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
