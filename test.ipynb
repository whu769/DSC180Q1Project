{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\halom\\anaconda3\\envs\\test\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "import torch\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"code_search_net\", \"all\")\n",
    "\n",
    "dataset_dict = datasets.load_from_disk(\"./Dataset/CodeSearchCorpus/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "CUDA device: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Testing if the pytorch GPU functions work\n",
    "print(torch.backends.cudnn.enabled)\n",
    "print(torch.cuda.is_available()) #We have GPU on deck and ready\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880853\n",
      "89154\n",
      "100529\n"
     ]
    }
   ],
   "source": [
    "# Seeing the size of the CodeSearchNet database\n",
    "print(len(dataset_dict[\"train\"]))\n",
    "print(len(dataset_dict[\"validation\"]))\n",
    "print(len(dataset_dict[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 1880853\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking only the training dataset\n",
    "train_dataset = dataset_dict[\"train\"]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 100529\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing the test_dataset\n",
    "test_dataset = dataset_dict[\"test\"]\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, 1.8M is too much. For week 5 at least, we've decided to train on a random sample of 10k from the training, 1k validation and 1k test\n",
    "\n",
    "Column for semantic search: func_documentation_string\n",
    "Column for tfidf: func_code_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository_name': 'ageitgey/face_recognition',\n",
       " 'func_path_in_repository': 'examples/face_recognition_knn.py',\n",
       " 'func_name': 'train',\n",
       " 'whole_func_string': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf',\n",
       " 'language': 'python',\n",
       " 'func_code_string': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf',\n",
       " 'func_code_tokens': ['def',\n",
       "  'train',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'model_save_path',\n",
       "  '=',\n",
       "  'None',\n",
       "  ',',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'None',\n",
       "  ',',\n",
       "  'knn_algo',\n",
       "  '=',\n",
       "  \"'ball_tree'\",\n",
       "  ',',\n",
       "  'verbose',\n",
       "  '=',\n",
       "  'False',\n",
       "  ')',\n",
       "  ':',\n",
       "  'X',\n",
       "  '=',\n",
       "  '[',\n",
       "  ']',\n",
       "  'y',\n",
       "  '=',\n",
       "  '[',\n",
       "  ']',\n",
       "  '# Loop through each person in the training set',\n",
       "  'for',\n",
       "  'class_dir',\n",
       "  'in',\n",
       "  'os',\n",
       "  '.',\n",
       "  'listdir',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ')',\n",
       "  ':',\n",
       "  'if',\n",
       "  'not',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'isdir',\n",
       "  '(',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'join',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  ')',\n",
       "  ':',\n",
       "  'continue',\n",
       "  '# Loop through each training image for the current person',\n",
       "  'for',\n",
       "  'img_path',\n",
       "  'in',\n",
       "  'image_files_in_folder',\n",
       "  '(',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'join',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  ')',\n",
       "  ':',\n",
       "  'image',\n",
       "  '=',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'load_image_file',\n",
       "  '(',\n",
       "  'img_path',\n",
       "  ')',\n",
       "  'face_bounding_boxes',\n",
       "  '=',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'face_locations',\n",
       "  '(',\n",
       "  'image',\n",
       "  ')',\n",
       "  'if',\n",
       "  'len',\n",
       "  '(',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '!=',\n",
       "  '1',\n",
       "  ':',\n",
       "  '# If there are no people (or too many people) in a training image, skip the image.',\n",
       "  'if',\n",
       "  'verbose',\n",
       "  ':',\n",
       "  'print',\n",
       "  '(',\n",
       "  '\"Image {} not suitable for training: {}\"',\n",
       "  '.',\n",
       "  'format',\n",
       "  '(',\n",
       "  'img_path',\n",
       "  ',',\n",
       "  '\"Didn\\'t find a face\"',\n",
       "  'if',\n",
       "  'len',\n",
       "  '(',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '<',\n",
       "  '1',\n",
       "  'else',\n",
       "  '\"Found more than one face\"',\n",
       "  ')',\n",
       "  ')',\n",
       "  'else',\n",
       "  ':',\n",
       "  '# Add face encoding for current image to the training set',\n",
       "  'X',\n",
       "  '.',\n",
       "  'append',\n",
       "  '(',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'face_encodings',\n",
       "  '(',\n",
       "  'image',\n",
       "  ',',\n",
       "  'known_face_locations',\n",
       "  '=',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '[',\n",
       "  '0',\n",
       "  ']',\n",
       "  ')',\n",
       "  'y',\n",
       "  '.',\n",
       "  'append',\n",
       "  '(',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  '# Determine how many neighbors to use for weighting in the KNN classifier',\n",
       "  'if',\n",
       "  'n_neighbors',\n",
       "  'is',\n",
       "  'None',\n",
       "  ':',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'int',\n",
       "  '(',\n",
       "  'round',\n",
       "  '(',\n",
       "  'math',\n",
       "  '.',\n",
       "  'sqrt',\n",
       "  '(',\n",
       "  'len',\n",
       "  '(',\n",
       "  'X',\n",
       "  ')',\n",
       "  ')',\n",
       "  ')',\n",
       "  ')',\n",
       "  'if',\n",
       "  'verbose',\n",
       "  ':',\n",
       "  'print',\n",
       "  '(',\n",
       "  '\"Chose n_neighbors automatically:\"',\n",
       "  ',',\n",
       "  'n_neighbors',\n",
       "  ')',\n",
       "  '# Create and train the KNN classifier',\n",
       "  'knn_clf',\n",
       "  '=',\n",
       "  'neighbors',\n",
       "  '.',\n",
       "  'KNeighborsClassifier',\n",
       "  '(',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'n_neighbors',\n",
       "  ',',\n",
       "  'algorithm',\n",
       "  '=',\n",
       "  'knn_algo',\n",
       "  ',',\n",
       "  'weights',\n",
       "  '=',\n",
       "  \"'distance'\",\n",
       "  ')',\n",
       "  'knn_clf',\n",
       "  '.',\n",
       "  'fit',\n",
       "  '(',\n",
       "  'X',\n",
       "  ',',\n",
       "  'y',\n",
       "  ')',\n",
       "  '# Save the trained KNN classifier',\n",
       "  'if',\n",
       "  'model_save_path',\n",
       "  'is',\n",
       "  'not',\n",
       "  'None',\n",
       "  ':',\n",
       "  'with',\n",
       "  'open',\n",
       "  '(',\n",
       "  'model_save_path',\n",
       "  ',',\n",
       "  \"'wb'\",\n",
       "  ')',\n",
       "  'as',\n",
       "  'f',\n",
       "  ':',\n",
       "  'pickle',\n",
       "  '.',\n",
       "  'dump',\n",
       "  '(',\n",
       "  'knn_clf',\n",
       "  ',',\n",
       "  'f',\n",
       "  ')',\n",
       "  'return',\n",
       "  'knn_clf'],\n",
       " 'func_documentation_string': 'Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.',\n",
       " 'func_documentation_tokens': ['Trains',\n",
       "  'a',\n",
       "  'k',\n",
       "  '-',\n",
       "  'nearest',\n",
       "  'neighbors',\n",
       "  'classifier',\n",
       "  'for',\n",
       "  'face',\n",
       "  'recognition',\n",
       "  '.'],\n",
       " 'split_name': 'train',\n",
       " 'func_code_url': 'https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition_knn.py#L46-L108'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing what one sample row of the training dataset is like\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverted_index_20000.pkl train_subset_embeddings_dataset_20000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Decide number of rows, the filepath to where to store the pickle files\n",
    "# The pickled objects are are the inverted index and embeddings dataset\n",
    "\n",
    "num_rows = 20000\n",
    "filepath_pkl_obj = \"./PickleObjects/\"\n",
    "inverted_index_name = f\"inverted_index_{num_rows}.pkl\"\n",
    "tsed_name = f\"train_subset_embeddings_dataset_{num_rows}.pkl\"\n",
    "\n",
    "print(inverted_index_name, tsed_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a sample of the training dataset\n",
    "# There are SO MANY PROBLEMS WHEN WE DO THIS THO, need to ask colin what to do i suppose?\n",
    "\n",
    "np.random.seed(1)\n",
    "train_subset_indices = np.random.choice(len(train_dataset), num_rows, replace = False)\n",
    "train_dataset_subset = train_dataset.select(train_subset_indices)\n",
    "\n",
    "len(train_dataset_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Embeddings Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following code from: https://huggingface.co/learn/nlp-course/chapter5/6?fw=pt\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model to the GPU. Mine is a 3060\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Hugging Face Tutorials\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train embeddings\n",
    "#If the filename exists, load the pickle object. If not, train it and then save it as a pickle object\n",
    "#REMEMBER TO KEEP THE FILENAMES THE SAME 0_0\n",
    "try:\n",
    "    with open(f'{filepath_pkl_obj}{tsed_name}', 'rb') as f:  # open a text file\n",
    "        train_subset_embeddings_dataset = pickle.load(f) # serialize the list\n",
    "        f.close()\n",
    "except:\n",
    "    train_subset_embeddings_dataset = train_dataset_subset.map(\n",
    "        lambda x: {\"embeddings\": get_embeddings(x[\"func_documentation_string\"]).detach().cpu().numpy()[0]}\n",
    "    )\n",
    "\n",
    "    with open(f'{filepath_pkl_obj}{tsed_name}', 'wb') as f:  # open a text file\n",
    "        pickle.dump(train_subset_embeddings_dataset, f) # serialize the list\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url', 'embeddings'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset_embeddings_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'load_config',\n",
       " '(',\n",
       " 'path',\n",
       " ')',\n",
       " ':',\n",
       " 'with',\n",
       " 'path',\n",
       " '.',\n",
       " 'open',\n",
       " '(',\n",
       " \"'rb'\",\n",
       " ')',\n",
       " 'as',\n",
       " 'fi',\n",
       " ':',\n",
       " 'file_bytes',\n",
       " '=',\n",
       " 'fi',\n",
       " '.',\n",
       " 'read',\n",
       " '(',\n",
       " ')',\n",
       " 'config',\n",
       " '=',\n",
       " 'yaml',\n",
       " '.',\n",
       " 'load',\n",
       " '(',\n",
       " 'file_bytes',\n",
       " '.',\n",
       " 'decode',\n",
       " '(',\n",
       " \"'utf-8'\",\n",
       " ')',\n",
       " ')',\n",
       " 'return',\n",
       " 'config']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_subset[0][\"func_code_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the embeddings to a pandas dataframe\n",
    "tsed_DF = train_subset_embeddings_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the code tokens. Super rudimentary, \n",
    "# as of right now, we're just taking rid of the single punctuation\n",
    "def clean_code_tokens(lst):\n",
    "    result = string.punctuation \n",
    "    new_lst = [] \n",
    "    for character in lst:\n",
    "        if character in result:\n",
    "            continue\n",
    "        else:\n",
    "            new_lst.append(character)\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column of \"clean\" code tokens\n",
    "# There's many many issues with this strategy\n",
    "tsed_DF[\"clean_code_tokens\"] =  tsed_DF[\"func_code_tokens\"].apply(clean_code_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Much of this code was based off of William Scott's implementation of TF-IDF: https://github.com/williamscott701/Information-Retrieval/blob/master/2.%20TF-IDF%20Ranking%20-%20Cosine%20Similarity%2C%20Matching%20Score/TF-IDF.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates s list of documents\n",
    "documents = tsed_DF[\"clean_code_tokens\"].to_dict()\n",
    "\n",
    "# Compiles a list of the words \n",
    "all_words = []\n",
    "for i in list(tsed_DF[\"clean_code_tokens\"].to_dict().values()):\n",
    "    all_words += i\n",
    "\n",
    "#convert all words to a set, eliminates, duplicates\n",
    "all_words = list(set(all_words)) #Get rid of all repeats\n",
    "all_words\n",
    "\n",
    "# Create the inverted index if its not in a pickle file (and save it)\n",
    "try:\n",
    "     with open(f'{filepath_pkl_obj}{inverted_index_name}', 'rb') as f:\n",
    "        inverted_index = pickle.load(f) # deserialize using load()\n",
    "        f.close()\n",
    "except:\n",
    "    inverted_index = {}\n",
    "\n",
    "    for word in all_words:\n",
    "            if word != \"\":\n",
    "                lst_docs = []\n",
    "                for i, doc in documents.items():\n",
    "                    if word in doc:\n",
    "                        lst_docs.append(i)\n",
    "            \n",
    "                inverted_index[word] = lst_docs\n",
    "    \n",
    "    #Pickle afterwards\n",
    "    with open(f'{filepath_pkl_obj}{inverted_index_name}', 'wb') as f:  # open a text file\n",
    "        pickle.dump(inverted_index, f) # serialize the list\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that the inverted index is right\n",
    "len(all_words) == len(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175692"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pickle inverted indices\n",
    "# Note: this is bad, that's an absurd amount of unique tokens. For code, \n",
    "# There needs to be much better tokenization or look into pre-trained embeddings\n",
    "len(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the document frequency of a word/token\n",
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = inverted_index[word]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if type(c) == list:\n",
    "        return len(c)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "# Creating a tf_idf object. WILL TURN THIS INTO A FUNCTION LATER\n",
    "tf_idf = {}\n",
    "for i in range(num_rows):\n",
    "    # print(i)\n",
    "    tokens = tsed_DF[\"clean_code_tokens\"].iloc[i]\n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token] / words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((num_rows + 1) / (df + 1))\n",
    "\n",
    "        tf_idf[i, token] = tf * idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the tf_idf object into a numpy array for much faster calculations\n",
    "all_words_dict = dict(zip(all_words, range(len(all_words))))\n",
    "\n",
    "\n",
    "tf_idf_array = np.zeros((num_rows, len(all_words)))\n",
    "\n",
    "for i in tf_idf:\n",
    "    try:\n",
    "        ind = all_words_dict[i[1]]\n",
    "        tf_idf_array[i[0]][ind] = tf_idf[i]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which given a query, returns in a tf_idf vector\n",
    "def gen_vector(s):\n",
    "    # This is where we'd do more processing of the query\n",
    "    tokens = s.split()\n",
    "\n",
    "    q_vector = np.zeros((len(all_words)))\n",
    "    \n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((num_rows+1)/(df+1))\n",
    "\n",
    "        try:\n",
    "            ind = all_words_dict[token]\n",
    "            q_vector[ind] = tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    return q_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175692,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making sure the method returns a vector of (len(all_words),) dimensions\n",
    "gen_vector(\"pandas how to select first 10 rows\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for cosine_similarity\n",
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to find the best match\n",
    "# query param: the string query\n",
    "# k param: the k number of results to return\n",
    "# alpha: the value which determines the linear split alpha * tfidf portion + (1-alpha)*semantic search portion\n",
    "def find_best_matches(query, k, alpha = 0.5):\n",
    "    q_vector = gen_vector(query)\n",
    "    q_embedding_vector = get_embeddings([query]).cpu().detach().numpy()[0]\n",
    "    \n",
    "    # print(q_vector)\n",
    "    # print(q_vector.shape)\n",
    "#     print(len(q_vector_space))\n",
    "#     print(len(q_vector_title))\n",
    "    \n",
    "    cosine_lst = [[x,0] for x in range(num_rows)]\n",
    "\n",
    "#     print(len(cosine_lst_title))\n",
    "#     print(len(cosine_lst_space))\n",
    "    \n",
    "    for i, x in enumerate(tf_idf_array):\n",
    "        # col = tfidf_DF[x].to_numpy()\n",
    "        # Tensor.cpu()\n",
    "        embedding = tsed_DF.iloc[i][\"embeddings\"]\n",
    "\n",
    "        cosine_lst[i] = [i, (alpha) * cosine_sim(q_vector, x) + (1 - alpha) * cosine_sim(q_embedding_vector, embedding)]\n",
    "    \n",
    "    \n",
    "    cosine_lst.sort(reverse = True, key = lambda x: x[1])\n",
    "    return cosine_lst[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which runs all 99 queries, and returns a pd df of the results\n",
    "def create_results(query_filepath, results_per_query = 100):\n",
    "    queries = pd.read_csv(query_filepath)\n",
    "    # display(queries)\n",
    "    q_lst = queries[\"query\"].to_list()\n",
    "    # print(q_lst)\n",
    "\n",
    "    lang_lst = []\n",
    "    func_code_url_lst = []\n",
    "    query_lst = []\n",
    "\n",
    "    for i, query in enumerate(q_lst):\n",
    "        print(i)\n",
    "        fbm_lst = find_best_matches(query, results_per_query, 0.2)\n",
    "        query_lst += [query for j in range(len(fbm_lst))]\n",
    "        \n",
    "        for lst in fbm_lst:\n",
    "            # print(tsed_DF.iloc[lst[0]][\"language\"])\n",
    "            # print(tsed_DF.iloc[lst[0]][\"func_name\"])\n",
    "            # print(tsed_DF.iloc[lst[0]][\"func_code_url\"])\n",
    "            # print(f\"SCORE: {lst[1]}\")\n",
    "            # print(\"-\" * 100)\n",
    "\n",
    "            lang_lst.append(tsed_DF.iloc[lst[0]][\"language\"])\n",
    "            func_code_url_lst.append(tsed_DF.iloc[lst[0]][\"func_code_url\"])\n",
    "        \n",
    "        # break\n",
    "\n",
    "    # print(lang_lst)\n",
    "    # print(func_code_url_lst)\n",
    "    # print(query_lst)\n",
    "    prediction_df = pd.DataFrame({'language' : lang_lst, 'url': func_code_url_lst, \"query\" : query_lst})\n",
    "    return prediction_df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = create_results(\"./Dataset/Testing/queries.csv\", results_per_query=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(\"./csv_output/baseline_20k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSC180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
