{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf from https://medium.com/@ashwinnaidu1991/creating-a-tf-idf-model-from-scratch-in-python-71047f16494e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"bee_movie.txt\", \"r\")\n",
    "text = f.read()\n",
    "text = text.replace('\\n', ' ')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "\n",
    "#convert to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "#remove punctuatiuon\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "#strip\n",
    "text = text.split()\n",
    "\n",
    "#remove stop words\n",
    "new_text = \"\"\n",
    "for word in text:\n",
    "    if word not in stopwords.words('english'):\n",
    "        new_text = new_text + \" \" + word\n",
    "words = new_text.split()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate tf\n",
    "def tf(text):\n",
    "    tf = {}\n",
    "    for word in words:\n",
    "        tf[word] = tf.get(word, 0) + 1\n",
    "    return tf\n",
    "tf = tf(words)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate idf\n",
    "def idf(text):\n",
    "    N = len(words)\n",
    "    idf = {}\n",
    "    for word in words:\n",
    "            idf[word] = idf.get(word, 0) + 1\n",
    "    for term, count in idf.items():\n",
    "        idf[term] = math.log(N / (count + 1))\n",
    "    return idf\n",
    "idf = idf(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate tf-idf\n",
    "tfidf = []\n",
    "tfidf_doc = {term: tf[term] * idf[term] for term in tf}\n",
    "tfidf.append(tfidf_doc)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create search function\n",
    "def search(query, tfidf):\n",
    "    query_tfidf = calculate_tfidf([query])[0]\n",
    "    results = []\n",
    "    for i, document in enumerate(documents):\n",
    "        similarity = sum(query_tfidf.get(term, 0) * tfidf[i].get(term, 0) for term in query_tfidf)\n",
    "        results.append((i, similarity))\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"simple example\"\n",
    "results = search(query, calculate_tfidf(documents))\n",
    "\n",
    "for i, similarity in results:\n",
    "    print(f\"Document {i}: Similarity {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "word_set = []\n",
    "\n",
    "for sent in text:\n",
    "    words = [word.lower() for word in word_tokenize(sent) if word.isalpha()]\n",
    "    sentences.append(words)\n",
    "    for word in words:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)\n",
    "\n",
    "# Set of words\n",
    "word_set = set(word_set)\n",
    "# total documents in our corpus\n",
    "total_docs = len(text)\n",
    "print('Total documents: ', total_docs)\n",
    "print('Total words: ', len(word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {}\n",
    "for i, word in enumerate(word_set):\n",
    "    word_index[word] = i\n",
    "\n",
    "def count_dict(sentences):\n",
    "    \"\"\"\n",
    "    Create a dictionary to keep the count of the number of documents containing the given word.\n",
    "    \"\"\"\n",
    "    count_dict = {}\n",
    "    for word in word_set:\n",
    "        count_dict[word] = 0\n",
    "    for sent in sentences:\n",
    "        for word in sent:\n",
    "            count_dict[word] += 1\n",
    "    return count_dict\n",
    "\n",
    "word_count = count_dict(sentences)\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(document, word):\n",
    "    \"\"\"\n",
    "    Calculate the term frequency of each word in the corpus.\n",
    "    \"\"\"\n",
    "    N = len(document)\n",
    "    occurance = len([token for token in document if token == word])\n",
    "    return occurance / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_document_frequency(word):\n",
    "    \"\"\"\n",
    "    Calculate the inverse document frequency of each word in the corpus.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        word_occurance = word_count[word] + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(total_docs / word_occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(sentence):\n",
    "    \"\"\"\n",
    "    Calculate the TF-IDF of each sentence in the corpus.\n",
    "    \"\"\"\n",
    "    vec = np.zeros((len(word_set),))\n",
    "    for word in sentence:\n",
    "        tf = term_frequency(sentence, word)\n",
    "        idf = inverse_document_frequency(word)\n",
    "        vec[word_index[word]] = tf * idf\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for sent in sentences:\n",
    "    vectors.append(tf_idf(sent))\n",
    "\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
